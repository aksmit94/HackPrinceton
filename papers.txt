  with a new deprivation (or ) function, in this paper, we theoretically study the changes in  with respect to the `global' mean and variance of the income distribution using indian survey data. we show that when the income obeys a log-normal distribution, a rising mean income generally indicates a reduction in  while an increase in the variance of the income distribution increases . this altruistic view for a developing economy, however, is not tenable anymore once the  index is found to follow a pareto distribution. here although a rising mean income indicates a reduction in , due to the presence of an inflexion point in the  function, there is a critical value of the variance below which  decreases with increasing variance while beyond this value,  undergoes a steep increase followed by a decrease with respect to higher variance. following these results, we make quantitative predictions to correlate a developing with a developed economy. 
  this paper introduces a general continuous form of  index that encompasses most of the existing formulas in the literature. we then propose a consistent estimator for this index in case the  line is a functional of the distribution. we also establish a uniform functional central limit theorem for the proposed estimator over a suitable product class of real-valued functions. as a consequence, testing procedures based either on single or simultaneously several  indices can be developed. a simulation study showing the asymptotic normality of the estimator is given as well as an application to real data for estimating the effect of relative  lines on the variance of the  estimates. 
  do today's communication technologies hold potential to alleviate ? the mobile phone's accessibility and use allows us with an unprecedented volume of data on social interactions, mobility and more. can this data help us better understand, characterize and alleviate  in one of the poorest nations in the world. our study is an attempt in this direction. we discuss two concepts, which are both interconnected and immensely useful for securing the important link between mobile accessibility and .   first, we use the cellular-communications data to construct virtual connectivity maps for senegal, which are then correlated with the  indicators to learn a model. our model predicts  index at any spatial resolution. thus, we generate  maps for senegal at an unprecedented finer resolution. such maps are essential for understanding what characterizes  in a certain region, and how it differentiates from other regions, for targeted responses for the demographic of the population that is most needy. an interesting fact, that is empirically proved by our methodology, is that a large portion of all communication, and economic activity in senegal is concentrated in dakar, leaving many other regions marginalized.   second, we study how user behavioral statistics, gathered from cellular-communications, correlate with the  indicators. can this relationship be learnt as a model to generate  maps at a finer resolution? surprisingly, this relationship can give us an alternate  map, that is solely based on the user behavior. since  is a complex phenomenon,  maps showcasing multiple perspectives, such as ours, provide policymakers with better insights for effective responses for  eradication. 
  current multidimensional measures of  continue to follow the traditional income  approach of using household rather than the individual as the unit of analysis. household level measures are gender blind since they ignore intra-household differences in resource allocation which have been shown to differ along gender lines. in this study we use new data from the karnataka household asset survey (khas) to construct an individual level multidimensional  measure for karnataka, india. our results show that an individual level measure can identify substantial gender differences in  that are masked at the household level. we also find a large potential for misclassification of poor individuals as non-poor when  is not assessed at the individual level. 
  we set general conditions under which the general  index, which summarizes all the available indices, is asymptotically represented with some empirical processes. this representation theorem offers a general key, in most directions, for the asymptotics of the bulk of  indices and issues in  analysis. our representation results uniformly hold on a large collection of  indices. they enable the continuous measure of  with longitudinal data. 
  we provide investment advice for an individual who wishes to minimize her lifetime , with a penalty for bankruptcy or ruin. we measure  via a non-negative, non-increasing function of (running) wealth. thus, the lower wealth falls and the longer wealth stays low, the greater the penalty. this paper generalizes the problems of minimizing the probability of lifetime ruin and minimizing expected lifetime occupation, with the  function serving as a bridge between the two. to illustrate our model, we compute the optimal investment strategies for a specific  function and two consumption functions, and we prove some interesting properties of those investment strategies. 
  mapping the spatial distribution of  in developing countries remains an important and costly challenge. these " maps" are key inputs for  targeting, public goods provision, political accountability, and impact evaluation, that are all the more important given the geographic dispersion of the remaining bottom billion severely poor individuals. in this paper we train convolutional neural networks (cnns) to estimate  directly from high and medium resolution satellite images. we use both planet and digital globe imagery with spatial resolutions of 3-5 sq. m. and 50 sq. cm. respectively, covering all 2 million sq. km. of mexico. benchmark  estimates come from the 2014 mcs-enigh combined with the 2015 intercensus and are used to estimate  rates for 2,456 mexican municipalities. cnns are trained using the 896 municipalities in the 2014 mcs-enigh. we experiment with several architectures (googlenet, vgg) and use googlenet as a final architecture where weights are fine-tuned from imagenet. we find that 1) the best models, which incorporate satellite-estimated land use as a predictor, explain approximately 57% of the variation in  in a validation sample of 10 percent of mcs-enigh municipalities; 2) across all mcs-enigh municipalities explanatory power reduces to 44% in a cnn prediction and landcover model; 3) predicted  from the cnn predictions alone explains 47% of the variation in  in the validation sample, and 37% over all mcs-enigh municipalities; 4) in urban areas we see slight improvements from using digital globe versus planet imagery, which explain 61% and 54% of  variation respectively. we conclude that cnns can be trained end-to-end on satellite imagery to estimate , although there is much work to be done to understand how the training process influences out of sample validation. 
  we introduce the general  index (gpi), which summarizes most of the known and available  indices, in the form {equation*} gpi=\delta (\frac{a(q_{n},n,z)}{nb(q,n)}\overset{q_{n}}{\underset{j=1}{\sum}%}w(\mu_{1}n+\mu_{2}q_{n}-\mu_{3}j+\mu_{4})d(\frac{z-y_{j,n}}{z}%)),{equation*} where {equation*} b(q_{n},n)=\sum_{j=1}^{q}w(j), {equation*} a(\cdot), w(\cdot),and d(\cdot) \ are given measurable functions, q_{n} is the number of the poor in the sample, z is the  line and y_{1,n}\leq y_{2,n}\leq ...\leq y_{n,n}\ are the ordered sampled incomes or expenditures of the individuals or households. we show here how the available indices based on the  gaps are derived from it. the asymptotic normality is then established and particularized for the usual  measures for immediate applications to poor countries data. 
  multidimensional  measurement has captured the attention of policy-makers and researchers during recent years. mexico is one of the most advanced countries in the measurement of  beyond income indicators. however, both in mexico and other countries which have attempted at measuring  from a multidimensional perspective, the environmental dimension, has been well under-represented. based on international evidence and, using the welfare-rights based methodological framework used in mexico to measure multi-dimensional  officially, the paper proposes an indicator and six sub-indicators for measuring the lack of a minimum welfare to fulfil the right to a healthy environment through 6 sub-indicators measuring effective access, quality and continuity with regards to water, energy, biodiversity, air, spatial health, waste management and the vulnerability to  from climate change impacts. 
  underprivileged students, especially in primary school, have shown to have less access to educational materials often resulting in general dissatisfaction in the school system and lower academic performance (saatcioglu and rury, 2012, p.23). the relationship between family socioeconomic status and student interest in academic endeavors, level of classroom engagement, and participation in extracurricular programs were analyzed. socioeconomic status was categorized as below  level, at or above  level, 100 to 199 percent of , and 200 percent of  or higher (united states census bureau). student interest, engagement, and persistence were measured as a scalar quantity of three variables: never, sometimes, and often. the participation of students in extracurricular activities was also compared based on the same categories of socioeconomic status. after running the multivariate analysis of variance, it was found that there was a statistically significant variance of student academic prosperity and  level. 
   maps are used to aid important political decisions such as allocation of development funds by governments and international organizations. those decisions should be based on the most accurate  figures. however, often reliable  figures are not available at fine geographical levels or for particular risk population subgroups due to the sample size limitation of current national surveys. these surveys cannot cover adequately all the desired areas or population subgroups and, therefore, models relating the different areas are needed to 'borrow strength" from area to area. in particular, the spanish survey on income and living conditions (silc) produces national  estimates but cannot provide  estimates by spanish provinces due to the poor precision of direct estimates, which use only the province specific data. it also raises the ethical question of whether  is more severe for women than for men in a given province. we develop a hierarchical bayes (hb) approach for  mapping in spanish provinces by gender that overcomes the small province sample size problem of the silc. the proposed approach has a wide scope of application because it can be used to estimate general nonlinear parameters. we use a bayesian version of the nested error regression model in which markov chain monte carlo procedures and the convergence monitoring therein are avoided. a simulation study reveals good frequentist properties of the hb approach. the resulting  maps indicate that , both in frequency and intensity, is localized mostly in the southern and western provinces and it is more acute for women than for men in most of the provinces. 
  the dynamics of economies and infectious disease are inexorably linked: economic well-being influences health (sanitation, nutrition, treatment capacity, etc.) and health influences economic well-being (labor productivity lost to sickness and disease). often societies are locked into " traps" of poor health and poor economy. here, using a simplified coupled disease-economic model with endogenous capital growth we demonstrate the formation of  traps, as well as ways to escape them. we suggest two possible mechanisms of escape both motivated by empirical data: one, through an influx of capital (development aid), and another through changing the percentage of gdp spent on healthcare. we find that a large influx of capital is successful in escaping the  trap, but increasing health spending alone is not. our results demonstrate that escape from a  trap may be possible, and carry important policy implications in the world-wide distribution of aid and within-country healthcare spending. 
  for the decomposability property is very a practical one in welfare analysis, most researchers and users favor decomposable  indices such as the foster-greer-thorbeck  index. this may lead to neglect the so important weighted indices like the kakwani and shorrocks ones which have interesting other properties in welfare analysis. to face up to this problem, we give in this paper, statistical estimations of the gap of decomposability of a large class of such indices using the general  indice (gpi) and of a new asymptotic representation theorem for it, in terms of functional empirical processes theory. the results then enable independent handling of targeted groups and next global reporting with significant confidence intervals. data-driven examples are given with real data. 
  we examine illinois educational data from standardized exams and analyze primary factors affecting the achievement of public school students. we focus on the simplest possible models: representation of data through visualizations and regressions on single variables. exam scores are shown to depend on school type, location, and  concentration. for most schools in illinois, student test scores decline linearly with  concentration. however chicago must be treated separately. selective schools in chicago, as well as some traditional and charter schools, deviate from this pattern based on . for any  level, chicago schools perform better than those in the rest of illinois. selective programs for gifted students show high performance at each grade level, most notably at the high school level, when compared to other illinois school types. the case of chicago charter schools is more complex. in the last six years, their students' scores overtook those of students in traditional chicago high schools. 
  the government of mexico's social development agency, sedesol, is responsible for the administration of social services and has the mission of lifting mexican families out of . one key challenge they face is matching people who have social service needs with the services sedesol can provide accurately and efficiently. in this work we describe two specific applications implemented in collaboration with sedesol to enhance their distribution of social services. the first problem relates to systematic underreporting on applications for social services, which makes it difficult to identify where to prioritize outreach. responding that five people reside in a home when only three do is a type of underreporting that could occur while a social worker conducts a home survey with a family to determine their eligibility for services. the second involves approximating multidimensional  profiles across households. that is, can we characterize different types of vulnerabilities -- for example, food insecurity and lack of health services -- faced by those in ?   we detail the problem context, available data, our machine learning formulation, experimental results, and effective feature sets. as far as we are aware this is the first time government data of this scale has been used to combat  within mexico. we found that survey data alone can suggest potential underreporting.   further, we found geographic features useful for housing and service related indicators and transactional data informative for other dimensions of . the results from our machine learning system for estimating  profiles will directly help better match 7.4 million individuals to social programs. 
  the lack of reliable data in developing countries is a major obstacle to sustainable development, food security, and disaster relief.  data, for example, is typically scarce, sparse in coverage, and labor-intensive to obtain. remote sensing data such as high-resolution satellite imagery, on the other hand, is becoming increasingly available and inexpensive. unfortunately, such data is highly unstructured and currently no techniques exist to automatically extract useful insights to inform policy decisions and help direct humanitarian efforts. we propose a novel machine learning approach to extract large-scale socioeconomic indicators from high-resolution satellite imagery. the main challenge is that training data is very scarce, making it difficult to apply modern techniques such as convolutional neural networks (cnn). we therefore propose a transfer learning approach where nighttime light intensities are used as a data-rich proxy. we train a fully convolutional cnn model to predict nighttime lights from daytime imagery, simultaneously learning features that are useful for  prediction. the model learns filters identifying different terrains and man-made structures, including roads, buildings, and farmlands, without any supervision beyond nighttime lights. we demonstrate that these learned features are highly informative for  mapping, even approaching the predictive performance of survey data collected in the field. 
  in a recent work (chattopadhyay, a. k. et al, europhys. lett. {\bf 91}, 58003, 2010) based on food consumption statistics, we showed how a stochastic agent based model could represent the time variation of the income distribution statistics in a developing economy, thereby defining an alternative \enquote{ index} (pi) that largely agreed with  gap index data. this pi used two variables, the probability density function of the income statistics and a consumption deprivation (cd) function, representing the shortfall in the minimum consumption needed for survival. since the time dependence of the cd function was introduced there through data extrapolation only and not through an endogenous time dependent series, this model left unexplained how the minimum consumption needed for survival varies with time. the present article overcomes these limitations and arrives at a new unified theoretical structure through time varying consumption and income distributions where trade is only allowed when the income exceeds consumption deprivation (cd). our results reveal that such cd-dynamics reduces the threshold level of consumption of basic necessities, suggesting a possible dietary transition in terms of lower saturation level of food-grain consumption. the new  index conforms to recently observed trends more closely than conventional measures of  and allows probabilistic prediction of pi for future times. 
  we present a stochastic agent-based model for the distribution of personal incomes in a developing economy. we start with the assumption that incomes are determined both by individual labour and by stochastic effects of trading and investment. the income from personal effort alone is distributed about a mean, while the income from trade, which may be positive or negative, is proportional to the trader's income. these assumptions lead to a langevin model with multiplicative noise, from which we derive a fokker-planck (fp) equation for the income probability density function (ipdf) and its variation in time. we find that high earners have a power-law income distribution while the low income groups have a levy ipdf. comparing our analysis with the indian survey data (obtained from the world bank website) taken over many years we obtain a near-perfect data collapse onto our model's equilibrium ipdf. the theory quantifies the economic notion of "given other things". using survey data to relate the ipdf to actual food consumption we define a  index, which is consistent with traditional indices, but independent of an arbitrarily chosen " line" and therefore less susceptible to manipulation. 
  we set in this paper a coherent theory based on functional empirical processes to consider both the  and the inequality indices in one gaussian field enabling to study the influence of the one on the other. we use the general  index (\textit{gpi}), that is a class of  indices covering the most common ones and a functional class of inequality measure including the entropy measure, the mean logarithmic deviation, the different inequality measures of atkinson, champernowne, kolm and theil called theil-like inequality measures \textit{tlim}. our results are given in a unified approach with respect to the two classes instead of their particular elements. we provide the asymptotic laws of the variations of each class over two given periods and the ratio of the variation and derive confidence intervals for them. although the variances may seem somehow complicated, we provide r codes for their computations and apply the results for the pseudo-panel data for senegal with simple analysis. 
  urban-rural gap and regional inequality are long standing problems in china and result in considerable number of studies. this paper examines the dynamic behaviors of incomes for both urban and rural areas with a prefectural data set. the analysis is conducted by using a distribution dynamics approach, which have advantages in examination on persistence, polarization and convergence clubs. the results show that persistence and immobility are the dominant characteristics in the income distribution dynamics. the prefectural urban and rural areas converge into their own steady states differentiated in income levels. this pattern of urban-rural gap also exists in three regional groups, namely the eastern, central and western regions. examination on the dynamics of the poorest areas shows that geographical  traps exist in both urban and rural prefectural areas. our results indicate that more policy interventions are required to narrow down the urban-rural gap and to eliminate the  traps in china. 
  we study the empirical decomposition of  indicators. this property is very important and convenient in the context of the fight against . indeed, it makes it possible to put in place sectoral  reduction policies on the basis of a relevant stratification laid down at the outset. the simultaneous impacts of these policies, measured as reduction gains over the population as a whole, is then obtained by aggregating those obtained at each stratum by a relatively simple formula. it turns out that indicators as important as those of sen and shorrocks do not verify this property contrary to the elements of the class of foster - greer and thorbecke. given the data from the 1996 senegalese survey of households (esam), we show that the lack of decomposability of these indicators on the income variable for several types of population stratification is practically zero , of the order of one to two per thousand. this makes it possible to use the decomposition of the sen and shorrocks indicators without any untoward consequences. an explanatory model of these results is presented for future research. 
  to understand a sentence like "whereas only 10% of white americans live at or below the  line, 28% of african americans do" it is important not only to identify individual facts, e.g.,  rates of distinct demographic groups, but also the higher-order relations between them, e.g., the disparity between them. in this paper, we propose the task of textual analogy parsing (tap) to model this higher-order meaning. the output of tap is a frame-style meaning representation which explicitly specifies what is shared (e.g.,  rates) and what is compared (e.g., white americans vs. african americans, 10% vs. 28%) between its component facts. such a meaning representation can enable new applications that rely on discourse understanding such as automated chart generation from quantitative text. we present a new dataset for tap, baselines, and a model that successfully uses an ilp to enforce the structural constraints of the problem. 
  discriminatory trade liberalization policies are becoming more popular among world economies. countries are motivated to enter for regional trade agreements to capture faster economic growth for alleviating . in developing economies like most of the member countries of the association of south east asian nations (asean), a sizeable portion of people are suffering from  by exposing them to food insecurity. low level of income and low productivity of agricultural sector have augmented the severity of food insecurity of those people. discriminatory trade liberalization policies are expected to reduce  and strengthen the food security. the objective of this paper is to examine the effect of asean free trade agreement (afta) on food security of its member countries. the multiple regression analysis in panel data was employed to disentangle the impacts of trade liberalization on food securit y with use of regional trade agreement dummy variable. the finding of the study supports that afta has influenced positively on food security of its member nations. after the formation of afta, the level of per-capita daily dietary energy supply of the member countries has been increased moderately over time. 
  published during a severe economic crisis, this study presents the first spatial microsimulation model for the analysis of income inequalities and  in greece. first, we present a brief overview of the method and discuss its potential for the analysis of multidimensional  and income inequality in greece. we then present the simathens model, based on a combination of small-area demographic and socioeconomic information available from the greek census of population with data from the european union statistics on income and living conditions (eu-silc). the model is based on an iterative proportional fitting (ipf) algorithm, and is used to reweigh eu-silc records to fit in small-area descriptions for athens based on 2001 and 2011 censuses. this is achieved by using demographic and socioeconomic characteristics as constraint variables. finally, synthesis of the labor market and occupations are chosen as the main variables for externally validating our results, in order to verify the integrity of the model. results of this external validation process are found to be extremely satisfactory, indicating a high goodness of fit between simulated and real values. finally, the study presents a number of model outputs, illustrating changes in social and economic geography, during a severe economic crisis, offering a great opportunity for discussing further potential of this model in policy analysis. 
  we analyze a conservative market model for the competition among economic agents in a close society. a minimum dynamics ensures that the poorest agent has a chance to improve its economic welfare. after a transient, the system self-organizes into a critical state where the wealth distribution have a minimum threshold, with almost no agent below this  line, also, very few extremely rich agents are stable in time. above the  line the distribution follows an exponential behavior. the local solution exhibits a low gini index, while the mean field solution of the model generates a wealth distribution similar to welfare states like sweden. 
  the phenomenon of white flight is often illustrated by the case of detroit whose population dropped from 1.80 million to 0.95 million between 1950 and 2000 while at the same time its black and hispanic component grew from 30 percent to 85 percent. but is this case really representative? the present paper shows that the phenomenon of white flight is in fact essentially a flight from . as a confirmation, we show that the changes in white or black populations are highly correlated which means that white flight is always paralleled by black flight (and hispanic flight as well). this broader interpretation of white flight accounts not only for the case of northern cities such as cincinnati, cleveland or detroit, but for all population changes at county level, provided the population density is higher than a threshold of about 50 per square-kilometer which corresponds to moderately urbanized areas (as can be found in states like indiana or virginia for instance). 
  evolution of science and engineering has led to the growth of several commercial applications. the wide spread implementation of commercial based applications has in turn directed the emergence of advanced technologies such as cloud computing. india has well proven itself as a potential hub for advanced technologies including cloud based industrial market. microfinance system has emerged out as a panacea to indian economy since the population encompasses of people who come under  and below  index. however, one of the key challenges in successful operation of microfinance system in india has given rise to integration of financial services using sophisticated cloud computing model. this paper, therefore propose a fundamental cloud-based microfinance model in order to reduce high transaction risks involved during microfinance operations in an inexpensive and efficient manner. 
  many models of market dynamics make use of the idea of conservative wealth exchanges among economic agents. a few years ago an exchange model using extremal dynamics was developed and a very interesting result was obtained: a self-generated minimum wealth or  line. on the other hand, the wealth distribution exhibited an exponential shape as a function of the square of the wealth. these results have been obtained both considering exchanges between nearest neighbors or in a mean field scheme. in the present paper we study the effect of distributing the agents on a complex network. we have considered archetypical complex networks: erd\"{o}s-r\'enyi random networks and scale-free networks. the presence of a  line with finite wealth is preserved but spatial correlations are important, particularly between the degree of the node and the wealth. we present a detailed study of the correlations, as well as the changes in the gini coefficient, that measures the inequality, as a function of the type and average degree of the considered networks. 
  poor economies not only produce less; they typically produce things that involve fewer inputs and fewer intermediate steps. yet the supply chains of poor countries face more frequent disruptions---delivery failures, faulty parts, delays, power outages, theft, government failures---that systematically thwart the production process. to understand how these disruptions affect economic development, we model an evolving input--output network in which disruptions spread contagiously among optimizing agents. the key finding is that a  trap can emerge: agents adapt to frequent disruptions by producing simpler, less valuable goods, yet disruptions persist. growing out of  requires that agents invest in buffers to disruptions. these buffers rise and then fall as the economy produces more complex goods, a prediction consistent with global patterns of input inventories. large jumps in economic complexity can backfire. this result suggests why "big push" policies can fail, and it underscores the importance of reliability and of gradual increases in technological complexity. 
  we describe a method to identify poor households in data-scarce countries by leveraging information contained in nationally representative household surveys. it employs standard statistical learning techniques---cross-validation and parameter regularization---which together reduce the extent to which the model is over-fitted to match the idiosyncracies of observed survey data. the automated framework satisfies three important constraints of this development setting: i) the prediction model uses at most ten questions, which limits the costs of data collection; ii) no computation beyond simple arithmetic is needed to calculate the probability that a given household is poor, immediately after data on the ten indicators is collected; and iii) one specification of the model (i.e. one scorecard) is used to predict  throughout a country that may be characterized by significant sub-national differences. using survey data from zambia, the model's out-of-sample predictions distinguish poor households from non-poor households using information contained in ten questions. 
  individuals in low socioeconomic brackets are considered at-risk for developing influenza-related complications and often exhibit higher than average influenza-related hospitalization rates. this disparity has been attributed to various factors, including restricted access to preventative and therapeutic health care, limited sick leave, and household structure. adequate influenza surveillance in these at-risk populations is a critical precursor to accurate risk assessments and effective intervention. however, the united states of america's primary national influenza surveillance system (ilinet) monitors outpatient healthcare providers, which may be largely inaccessible to lower socioeconomic populations. recent initiatives to incorporate internet-source and hospital electronic medical records data into surveillance systems seek to improve the timeliness, coverage, and accuracy of outbreak detection and situational awareness. here, we use a flexible statistical framework for integrating multiple surveillance data sources to evaluate the adequacy of traditional (ilinet) and next generation (biosense 2.0 and google flu trends) data for situational awareness of influenza across  levels. we find that zip codes in the highest  quartile are a critical blind-spot for ilinet that the integration of next generation data fails to ameliorate. 
  this paper combines ideas from classical economics and modern finance with the general lotka-volterra models of levy &amp; solomon to provide straightforward explanations of wealth and income distributions. using a simple and realistic economic formulation, the distributions of both wealth and income are fully explained. both the power tail and the log-normal like body are fully captured. it is of note that the full distribution, including the power law tail, is created via the use of absolutely identical agents. it is further demonstrated that a simple scheme of compulsory saving could eliminate  at little cost to the taxpayer. 
  we develop constrained bayesian estimation methods for small area problems: those requiring smoothness with respect to similarity across areas, such as geographic proximity or clustering by covariates; and benchmarking constraints, requiring (weighted) means of estimates to agree across levels of aggregation. we develop methods for constrained estimation decision-theoretically and discuss their geometric interpretation. our constrained estimators are the solutions to tractable optimization problems and have closed-form solutions. mean squared errors of the constrained estimators are calculated via bootstrapping. our techniques are free of distributional assumptions and apply whether the estimator is linear or non-linear, univariate or multivariate. we illustrate our methods using data from the u.s. census's small area income and  estimates program. 
  we compare two prioritization schemes for the components of flooding vulnerability: urbanized area ration, literacy rate, mortality rate, , radiotv penetration, non-structural measures and structural measure. we prioritize the components, giving each a weight. we then express the vulnerability function as a weighted sum of its components. this weighted sum serves as the fitness function in a genetic algorithm, which comes up with the optimal design for a flood-resistant city. 
  we analyze the coauthorship production of the aaep annual meeting since 1964. we use social network analysis for creating coauthorship networks and given that any paper must be tagged with two jel codes, we use this information for also structuring a thematic network. then we calculate network metrics and find main actors and clusters for coauthors and topics. we distinguish a gender gap in the sample. thematic networks show a cluster of codes and the analysis of the cluster shows the preeminence of the tags related to trade, econometric, distribution and health and education topics. 
  we analyze the decisive role played by the complexity of economic systems at the onset of the industrialization process of countries over the past 50 years. our analysis of the input growth dynamics, based on a recently introduced measure of economic complexity, reveals that more differentiated and more complex economies face a lower barrier (in terms of gdp per capita) when starting the transition towards industrialization. moreover, adding the complexity dimension to the industrialization process description helps to reconcile current theories with empirical findings. 
  in this paper, a frequency coefficient based on the sen-shorrocks-thon (sst)  index notion is proposed. the clustering sst index can be used as the method for determination of the connection between similar neighbor sub-clusters. consequently, connections can reveal existence of natural homogeneous. through estimation of the connection strength, we can also verify information about the estimated number of natural clusters that is necessary assumption of efficient market segmentation and campaign management and financial decisions. the index can be used as the complementary tool for the u-matrix visualization. the index is tested on an artificial dataset with known parameters and compared with results obtained by the unified-distance matrix method. 
  in this thesis i present various algorithms for the unsupervised machine learning of aspects of natural languages using a variety of statistical models. the scientific object of the work is to examine the validity of the so-called argument from the  of the stimulus advanced in favour of the proposition that humans have language-specific innate knowledge. i start by examining an a priori argument based on gold's theorem, that purports to prove that natural languages cannot be learned, and some formal issues related to the choice of statistical grammars rather than symbolic grammars. i present three novel algorithms for learning various parts of natural languages: first, an algorithm for the induction of syntactic categories from unlabelled text using distributional information, that can deal with ambiguous and rare words; secondly, a set of algorithms for learning morphological processes in a variety of languages, including languages such as arabic with non-concatenative morphology; thirdly an algorithm for the unsupervised induction of a context-free grammar from tagged text. i carefully examine the interaction between the various components, and show how these algorithms can form the basis for a empiricist model of language acquisition. i therefore conclude that the argument from the  of the stimulus is unsupported by the evidence. 
  classic economic science is reaching the limits of its explanatory powers. complexity science uses an increasingly larger set of different methods to analyze physical, biological, cultural, social, and economic factors, providing a broader understanding of the socio-economic dynamics involved in the development of nations worldwide. the use of tools developed in the natural sciences, such as thermodynamics, evolutionary biology, and analysis of complex systems, help us to integrate aspects, formerly reserved to the social sciences, with the natural sciences. this integration reveals details of the synergistic mechanisms that drive the evolution of societies. by doing so, we increase the available alternatives for economic analysis and provide ways to increase the efficiency of decision-making mechanisms in complex social contexts. this interdisciplinary analysis seeks to deepen our understanding of why chronic  is still common, and how the emergence of prosperous technological societies can be made possible. this understanding should increase the chances of achieving a sustainable, harmonious and prosperous future for humanity. the analysis evidences that complex fundamental economic problems require multidisciplinary approaches and rigorous application of the scientific method if we want to advance significantly our understanding of them. the analysis reveals viable routes for the generation of wealth and the reduction of , but also reveals huge gaps in our knowledge about the dynamics of our societies and about the means to guide social development towards a better future for all. 
  in this work we combing models of disease dynamics and economic production, and we show the potential implications of this for demonstrating the importance of savings for buffering an economy during the period of an epidemic.   finding an explicit function that relates  and the production of a community is an almost impossible task because of the number of variables and parameters that should be taken into account. however, studying the dynamics of an endemic disease in a region that affects its population, and therefore its ability to work, is an honest approach to understanding this function. we propose a model, perhaps the simplest, that couples two dynamics, the dynamics of an endemic disease and the dynamics of a closed economy of products and goods that the community produces in the epidemic period.   some of the results of this study are expected and known in the literature but some others are not. we highlight three of them: the interdependence that exists between health and the product of that economy. the majority of the known results only show the dependence in a single direction. another of the most important goals in this work is to show the existence of a  malthusian trap in economies with low levels of capital investment due to pandemic disease. and another is to show that there is an optimal level of savings that maximizes the \emph{per capita} product of the economy, which is machiavellian, but has important implications for market efficiency. the model tells us why saving is important in an aggregate economy despite being affected by an epidemic. 
  through seven publications this dissertation shows how anonymized mobile phone data can contribute to the social good and provide insights into human behaviour on a large scale. the size of the datasets analysed ranges from 500 million to 300 billion phone records, covering millions of people. the key contributions are two-fold:   1. big data for social good: through prediction algorithms the results show how mobile phone data can be useful to predict important socio-economic indicators, such as income, illiteracy and  in developing countries. such knowledge can be used to identify where vulnerable groups in society are, reduce economic shocks and is a critical component for monitoring  rates over time. further, the dissertation demonstrates how mobile phone data can be used to better understand human behaviour during large shocks in society, exemplified by an analysis of data from the terror attack in norway and a natural disaster on the south-coast in bangladesh. this work leads to an increased understanding of how information spreads, and how millions of people move around. the intention is to identify displaced people faster, cheaper and more accurately than existing survey-based methods.   2. big data for efficient marketing: finally, the dissertation offers an insight into how anonymised mobile phone data can be used to map out large social networks, covering millions of people, to understand how products spread inside these networks. results show that by including social patterns and machine learning techniques in a large-scale marketing experiment in asia, the adoption rate is increased by 13 times compared to the approach used by experienced marketers. a data-driven and scientific approach to marketing, through more tailored campaigns, contributes to less irrelevant offers for the customers, and better cost efficiency for the companies. 
  endogenous, ideas-led, growth theory and agent based modelling with neighbourhood effects literature are crossed. in an economic overlapping generations framework, it is shown how social interactions and neighbourhood effects are of vital importance in the endogenous determination of the long run number of skilled workers and therefore of the growth prospects of an economy. neighbourhood effects interact with the initial distribution of educated agents across space and play a key role in the long run stabilisation of the number of educated individuals. our model implies a tendency towards segregation, with a possibly positive influence on growth, if team effects operate. the long run growth rate is also shown to depend on the rate of time preference. initial circumstances are of vital importance for long run outcomes. a poor initial education endowment will imply a long run reduced number of skilled workers and a mediocre growth rate, so there no economic convergence tendency. on the contrary, poor societies will grow less, or will even fall into a  trap, and will diverge continuously from richer ones. 
  biomimetic nanotechnology is a prominent research area at the meeting place of life sciences with engineering and physics: it is a continuously growing field that deals with knowledge transfer from biology to nanotechnology. biomimetic nanotechnology is a field that has the potential to substantially support successful mastering of major global challenges. the millennium project was commissioned by the united nations secretary-general in 2002 to develop a concrete action plan for the world to reverse the grinding , hunger and disease affecting billions of people. it states 15 global challenges: sustainable development, water, population and resources, democratization, long-term perspectives, information technology, the rich-poor gap, health, capacity to decide, peace and conflict, status of women, transnational crime, energy, science and technology and global ethics. the possible contributions to master these challenges with the help of biomimetic nanotechnology will be discussed in detail. 
  public debt is one of the important economic variables that quantitatively describes a nation's economy. because bankruptcy is a risk faced even by institutions as large as governments (e.g. iceland), national debt should be strictly controlled with respect to national wealth. also, the problem of eliminating extreme  in the world is closely connected to the study of extremely poor debtor nations. we analyze the time evolution of national public debt and find "convergence": initially less-indebted countries increase their debt more quickly than initially more-indebted countries. we also analyze the public debt-to-gdp ratio r, a proxy for default risk, and approximate the probability density function p(r) with a gamma distribution, which can be used to establish thresholds for sustainable debt. we also observe "convergence" in r: countries with initially small r increase their r more quickly than countries with initially large r. the scaling relationships for debt and r have practical applications, e.g. the maastricht treaty requires members of the european monetary union to maintain r &lt; 0.6. 
  rajasthan is the biggest state of india and is currently in the second phase of demographic transition and is moving towards the third phase of demographic transition with very slow pace. however, state's population will continue to grow for a time period. rajasthan's performance in the social and economic sector has been poor in past. the poor performance is the outcome of , illiteracy and poor development, which co-exist and reinforce each other. there are many demographic and socio-economic factors responsible for population growth. this paper attempts to identify the demographic and socio-economic variables, which are responsible for population growth in rajasthan with the help of multivariate analysis. 
  social unrest may reflect a variety of factors such as , unemployment, and social injustice. despite the many possible contributing factors, the timing of violent protests in north africa and the middle east in 2011 as well as earlier riots in 2008 coincides with large peaks in global food prices. we identify a specific food price threshold above which protests become likely. these observations suggest that protests may reflect not only long-standing political failings of governments, but also the sudden desperate straits of vulnerable populations. if food prices remain high, there is likely to be persistent and increasing global social disruption. underlying the food price peaks we also find an ongoing trend of increasing prices. we extrapolate these trends and identify a crossing point to the domain of high impacts, even without price peaks, in 2012-2013. this implies that avoiding global food crises and associated social unrest requires rapid and concerted action. 
  this paper adopts and adapts kohonen's standard self-organizing map (som) for exploratory temporal structure analysis. the self-organizing time map (sotm) implements som-type learning to one-dimensional arrays for individual time units, preserves the orientation with short-term memory and arranges the arrays in an ascending order of time. the two-dimensional representation of the sotm attempts thus twofold topology preservation, where the horizontal direction preserves time topology and the vertical direction data topology. this enables discovering the occurrence and exploring the properties of temporal structural changes in data. for representing qualities and properties of sotms, we adapt measures and visualizations from the standard som paradigm, as well as introduce a measure of temporal structural changes. the functioning of the sotm, and its visualizations and quality and property measures, are illustrated on artificial toy data. the usefulness of the sotm in a real-world setting is shown on , welfare and development indicators. 
  this paper takes an information visualization perspective to visual representations in the general som paradigm. this involves viewing som-based visualizations through the eyes of bertin's and tufte's theories on data graphics. the regular grid shape of the self-organizing map (som), while being a virtue for linking visualizations to it, restricts representation of cluster structures. from the viewpoint of information visualization, this paper provides a general, yet simple, solution to projection-based coloring of the som that reveals structures. first, the proposed color space is easy to construct and customize to the purpose of use, while aiming at being perceptually correct and informative through two separable dimensions. second, the coloring method is not dependent on any specific method of projection, but is rather modular to fit any objective function suitable for the task at hand. the cluster coloring is illustrated on two datasets: the iris data, and welfare and  indicators. 
  a conceptual area is divided into units or barangays, each was allowed to evolve under a physical constraint. a risk assessment method was then used to identify the flood risk in each community using the following risk factors: the area's urbanized area ratio, literacy rate, mortality rate,  incidence, radiotv penetration, and state of structural and non-structural measures. vulnerability is defined as a weighted-sum of these components. a penalty was imposed for reduced vulnerability. optimization comparison was done with matlab's genetic algorithms and simulated annealing; results showed 'extreme' solutions and realistic designs, for simulated annealing and genetic algorithm, respectively. 
  recent studies have shown the value of mobile phone data to tackle problems related to economic development and humanitarian action. in this research, we assess the suitability of indicators derived from mobile phone data as a proxy for food security indicators. we compare the measures extracted from call detail records and airtime credit purchases to the results of a nationwide household survey conducted at the same time. results show high correlations (&gt; .8) between mobile phone data derived indicators and several relevant food security variables such as expenditure on food or vegetable consumption. this correspondence suggests that, in the future, proxies derived from mobile phone data could be used to provide valuable up-to-date operational information on food security throughout low and middle income countries. 
  a subjective expected utility policy making centre, managing complex, dynamic systems, needs to draw on the expertise of a variety of disparate panels of experts and integrate this information coherently. to achieve this, diverse supporting probabilistic models need to be networked together, the output of one model providing the input to the next. in this paper we provide a technology for designing an integrating decision support system and to enable the centre to explore and compare the efficiency of different candidate policies. we develop a formal statistical methodology to underpin this tool. in particular, we derive sufficient conditions that ensure inference remains coherent before and after relevant evidence is accommodated into the system. the methodology is illustrated throughout using examples drawn from two decision support systems: one designed for nuclear emergency crisis management and the other to support policy makers in addressing the complex challenges of food  in the uk. 
  indonesian traditional villagers have a tradition for the sake of their own social and economic security named 'nyumbang'. there are wide variations of the traditions across the archipelago, and we revisit an observation to one in subang, west java, indonesia. the paper discusses and employs the evolutionary game theoretic insights to see the process of 'gantangan', of the intertwining social cohesion and economic expectation of the participation within the traditional activities. the current development of the gantangan tradition is approached and generalized to propose a view between the economic and social sphere surrounding modern people. while some explanations due to the current development of gantangan is drawn, some aspects related to traditional views complying the modern life with social and economic expectations is outlined. 
  we have developed an evolutionary game model, where agents can choose between two forms of social participation: interaction via online social networks and interaction by exclusive means of face-to-face encounters. we illustrate the societal dynamics that the model predicts, in light of the empirical evidence provided by previous literature. we then assess their welfare implications. we show that dynamics, starting from a world in which online social interaction is less gratifying than offline encounters, will lead to the extinction of the sub-population of online networks users, thereby making facebook and alike disappear in the long run. furthermore, we show that the higher the propensity for discrimination between the two sub-populations of socially active individuals, the greater the probability that individuals will ultimately segregate themselves, making society fall into a social  trap. 
  data mining revealed a cluster of economic, psychological, social and cultural indicators that in combination predicted corruption and wealth of european nations. this prosperity syndrome of self-reliant citizens, efficient division of labor, a sophisticated scientific community, and respect for the law, was clearly distinct from that of poor countries that had a diffuse relationship between high corruption perception, low gdpcapita, high social inequality, low scientific development, reliance on family and friends, and languages with many words for guilt. this suggests that there are many ways for a nation to be poor, but few ones to become rich, supporting the existence of synergistic interactions between the components in the prosperity syndrome favoring economic growth. no single feature was responsible for national prosperity. focusing on synergies rather than on single features should improve our understanding of the transition from  and corruption to prosperity in european nations and elsewhere. 
  the aim of this paper is to establish the asymptotic behavior of the mutual influence of the gini index and the  measures by using the gaussian fields described in mergane and lo(2013). the results are given as representation theorems using the gaussian fields of the unidimensional or the bidimensional functional brownian bridges. such representations, when combined with those already available, lead to joint asymptotic distributions with other statistics of interest like growth, welfare and inequality indices and then, unveil interesting results related to the mutual influence between them. the results are also appropriate for studying whether a growth is fair or not, depending on the variation of the inequality measure. datadriven applications are also available. although the variances may seem complicated at a first sight, their computations which are needed to get confidence intervals of the indices, are possible with the help of r codes we provide. beyond the current results, the provided representations are useful in connection with different ones of other statistics. 
  the ministry of social development in mexico is in charge of creating and assigning social programmes targeting specific needs in the population for the improvement of quality of life. to better target the social programmes, the ministry is aimed to find clusters of households with the same needs based on demographic characteristics as well as  conditions of the household. available data consists of continuous, ordinal, and nominal variables and the observations are not iid but come from a survey sample based on a complex design. we propose a bayesian nonparametric mixture model that jointly models this mixed scale data and accommodates for the different sampling probabilities. the performance of the model is assessed via simulated data. a full analysis of socio-economic conditions in households in the state of mexico is presented. 
  in the spirit of recent asymptotic works on the general  index (gpi) in the field of welfare analysis, the asymptotic representation of the non-decomposable takayama's index, which has failed to be incorporated in the unified gpi approach, is addressed and established here. this representation allows also to extend to it, recent results of statistical decomposability gaps estimations. the theoretical results are applied to real databases. the conclusions of the undertaken applications recommend to use takayama's index as a practically decomposable one, in virtue of the low decomposability gaps with respect to the large values of the index. 
  energy has always been the driving force in the technological and economic development of societies. the consumption of a significant amount of energy is required to provide basic living conditions of developed countries (heating, transportation, lighting, etc.). today energy supply has a considerable impact on the environment, since it is fuelled by the burning of fossil fuels. in addition to this, the fossil fuel reserves are decreasing while the demand for energy is rapidly rising. climate change, the depletion and geographical segregation of fossil fuel resources, health related issues as well as energy  constitute the driving forces towards the pursuit of alternative energy sources. in addition, countries with no access to oil reserves are being dependent from other countries for their energy supply, with a strong impact on politics and financial issues. 
  the rates of respiratory prescriptions vary by gp surgery across scotland, suggesting there are sizeable health inequalities in respiratory ill health across the country. the aim of this paper is to estimate the magnitude, spatial pattern and drivers of this spatial variation. monthly data on respiratory prescriptions are available at the gp surgery level, which creates an interesting methodological challenge as these data are not the classical geostatistical, areal unit or point process data types. a novel process-convolution model is proposed, which extends existing methods by being an adaptive smoother via a random weighting scheme and using a tapering function to reduce the computational burden. the results show that particulate air pollution,  and ethnicity all drive the health inequalities, while there are additional regional inequalities in rates after covariate adjustment. 
  ratio of medians or other suitable quantiles of two distributions is widely used in medical research to compare treatment and control groups or in economics to compare various economic variables when repeated cross-sectional data are available. inspired by the so-called growth incidence curves introduced in  research, we argue that the ratio of quantile functions is a more appropriate and informative tool to compare two distributions. we present an estimator for the ratio of quantile functions and develop corresponding simultaneous confidence bands, which allow to assess significance of certain features of the quantile functions ratio. derived simultaneous confidence bands rely on the asymptotic distribution of the quantile functions ratio and do not require re-sampling techniques. the performance of the simultaneous confidence bands is demonstrated in simulations. analysis of the expenditure data from uganda in years 1999, 2002 and 2005 illustrates the relevance of our approach. 
  obtaining detailed and reliable data about local economic livelihoods in developing countries is expensive, and data are consequently scarce. previous work has shown that it is possible to measure local-level economic livelihoods using high-resolution satellite imagery. however, such imagery is relatively expensive to acquire, often not updated frequently, and is mainly available for recent years. we train cnn models on free and publicly available multispectral daytime satellite images of the african continent from the landsat 7 satellite, which has collected imagery with global coverage for almost two decades. we show that despite these images' lower resolution, we can achieve accuracies that exceed previous benchmarks. 
  syntactic rules in natural language typically need to make reference to hierarchical sentence structure. however, the simple examples that language learners receive are often equally compatible with linear rules. children consistently ignore these linear explanations and settle instead on the correct hierarchical one. this fact has motivated the proposal that the learner's hypothesis space is constrained to include only hierarchical rules. we examine this proposal using recurrent neural networks (rnns), which are not constrained in such a way. we simulate the acquisition of question formation, a hierarchical transformation, in a fragment of english. we find that some rnn architectures tend to learn the hierarchical rule, suggesting that hierarchical cues within the language, combined with the implicit architectural biases inherent in certain rnns, may be sufficient to induce hierarchical generalizations. the likelihood of acquiring the hierarchical generalization increased when the language included an additional cue to hierarchy in the form of subject-verb agreement, underscoring the role of cues to hierarchy in the learner's input. 
  we interact with each other and our environment in rich and complex ways. these interactions form socioecological systems in which human, economic, or natural resources are used and replenished. in 2015, the united nations set seventeen sustainable development goals (sdgs) to attempt to change the way we live and create by 2030 a sustainable future balancing equitable prosperity within planetary boundaries. we have tended to tackle sdgs in isolation and now we realise that a key hurdle to sdg implementation are conflicts arising from sdg interactions. we estimate here for the first time the sustainome, a global picture of those interactions, and determine the main hurdles to maximising sdg implementation. we show that the relative contribution of sdgs to global sustainable success differ by country income. sdg conflicts within the sustainome mean that we must find new ways to address the impacts of climate change, approaches to reducing inequalities and responsible consumption. focussing on  alleviation and reducing inequalities will also have compounded positive effects on the sustainome. this network approach to sustainability provides a way to prioritise sdg and contextualise targets. 
  this research model uses an emancipatory approach to address challenges of equity in the science, technology, engineering, and math (stem) workforce. serious concerns about low minority participation call for a rigorous evaluation of new pedagogical methods that effectively prepares underrepresented groups for the increasingly digital world. the inability to achieve stem workforce diversity goals is attributed to the failure of the academic pipeline to maintain a steady flow of underrepresented minority students. formal curriculum frequently results in under-preparedness and a professional practices gap. exacerbating lower performance are fragile communities where issues such as , single-parent homes, incarceration, abuse, and homelessness disengage residents. since data shows that more minorities have computing and engineering degrees than work in the field, this discussions explores how educational institutions can critically examine social and political realities that impede stem diversity while capturing cultural cues that identify personal barriers amongst underrepresented groups. 
  in this work, we explore the ability of artificial neural networks to judge the grammatical acceptability of a sentence. machine learning research of this kind is well placed to answer important open questions about the role of prior linguistic bias in language acquisition by providing a test for the  of the stimulus argument. in service of this goal, we introduce the corpus of linguistic acceptability (cola), a set of 10,657 english sentences labeled as grammatical or ungrammatical by expert linguists. we train several recurrent neural networks to do binary acceptability classification. these models set a baseline for the task. error-analysis testing the models on specific grammatical phenomena reveals that they learn some systematic grammatical generalizations like subject-verb-object word order without any grammatical supervision. we find that neural sequence models show promise on the acceptability classification task. however, human-like performance across a wide range of grammatical constructions remains far off. 
  in the 21st century ongoing rapid urbanization highlights the need to gain deeper insights into the social structure of cities. while work on this challenge can profit from abundant data sources, the complexity of this data itself proves to be a challenge. in this paper we use diffusion maps, a manifold learning method, to discover hidden manifolds in the uk 2011 census data set. the census key statistics and quick statistics report 1450 different statistical features for each census output area. here we focus primarily on the city of bristol and the surrounding countryside, comprising 3490 of these output areas. our analysis finds the main variables that span the census responses, highlighting that university student density and  are the most important explanatory variables of variation in census responses. 
  the prominent inequality of wealth and income is a huge concern especially in the united states. the likelihood of diminishing  is one valid reason to reduce the world's surging level of economic inequality. the principle of universal moral equality ensures sustainable development and improve the economic stability of a nation. governments in different countries have been trying their best to address this problem and provide an optimal solution. this study aims to show the usage of machine learning and data mining techniques in providing a solution to the income equality problem. the uci adult dataset has been used for the purpose. classification has been done to predict whether a person's yearly income in us falls in the income category of either greater than 50k dollars or less equal to 50k dollars category based on a certain set of attributes. the gradient boosting classifier model was deployed which clocked the highest accuracy of 88.16%, eventually breaking the benchmark accuracy of existing works. 
  in the analysis of  and social exclusion, indicators of living conditions are some interesting non-monetary complements to the usual measurements in terms of current or annual income. living conditions depend in fact on longer term factors than income, and provide further information on households' actual resources that allow to compare more accurately between living standards. but in counterpart, a difficulty comes from the qualitative nature of the information, and the large number of dimensions and items that may be taken into account; in other words, living conditions are difficult to "measure". a consequence is that very often, the information is either used only partly, or reduced into a global score of (bad) living conditions, that results from counting "negative" items, and the qualitative dimension is lost. in this paper, we propose to use the kohonen algorithm first to describe how the elements of living conditions are combined, and secondly to classify households according to their living conditions. the main interest of a classification is to make appear not only quantitative differences in the "levels" of living conditions, but also qualitative differences within similar "levels". 
  colon and rectum cancer share many risk factors, and are often tabulated together as ``colorectal cancer'' in published summaries. however, recent work indicating that exercise, diet, and family history may have differential impacts on the two cancers encourages analyzing them separately, so that corresponding public health interventions can be more efficiently targeted. we analyze colon and rectum cancer data from the minnesota cancer surveillance system from 1998--2002 over the 16-county twin cities (minneapolis--st. paul) metro and exurban area. the data consist of two marked point patterns, meaning that any statistical model must account for randomness in the observed locations, and expected positive association between the two cancer patterns. our model extends marked spatial point pattern analysis in the context of a log gaussian cox process to accommodate spatially referenced covariates (local  rate and location within the metro area), individual-level risk factors (patient age and cancer stage), and related interactions. we obtain smoothed maps of marginal log-relative intensity surfaces for colon and rectum cancer, and uncover significant age and stage differences between the two groups. this encourages more aggressive colon cancer screening in the inner twin cities and their southern and western exurbs, where our model indicates higher colon cancer relative intensity. 
  we have seen in last few decades that the progress of information technology with leaps and bounds, which have completely changed the way of life in the developed nations. while internet has changed the established working practice and opened new vistas and provided a platform to connect, this gives the opportunity for collaborative work space that goes beyond the global boundary. ict promises a fundamental change in all aspects of our lives, including knowledge dissemination, social interaction, economic and business practices, political engagement, media, education, health, leisure and entertainment...this paper introduces the application of ict for rural development. the paper aims at improving the delivery of information to rural masses such as, technology information, marketing information, and information advice. this paper focuses digital divide and  eradication, good governance and the significance of internet for rural development. the paper concludes that icts offer the developing country, the opportunity to look ahead several stages of rural development by the use of internet. effective use of ict can demolish geographical boundaries and can bring rural communities closer to global economic systems and be of meaningful help to the underprivileged. 
  mobile cloud computing (mcc) is the state-ofthe- art mobile computing technology aims to alleviate resource  of mobile devices. recently, several approaches and techniques have been proposed to augment mobile devices by leveraging cloud computing. however, long-wan latency and trust are still two major issues in mcc that hinder its vision. in this paper, we analyze mcc and discuss its issues. we leverage service oriented architecture (soa) to propose an arbitrated multi-tier infrastructure model named sami for mcc. our architecture consists of three major layers, namely soa, arbitrator, and infrastructure. the main strength of this architecture is in its multi-tier infrastructure layer which leverages infrastructures from three main sources of clouds, mobile network operators (mnos), and mnos' authorized dealers. on top of the infrastructure layer, an arbitrator layer is designed to classify services and allocate them the suitable resources based on several metrics such as resource requirement, latency and security. utilizing sami facilitate development and deployment of service-based platform-neutral mobile applications. 
  mobility of economically underprivileged residents in china has seldom been well profiled due to privacy issue and the characteristics of chinese over . in this paper, we identify and characterize underprivileged residents in beijing using ubiquitous public transport smartcard transactions in 2008 and 2010, respectively. we regard these frequent busmetro riders (frs) in china, especially in beijing, as economically underprivileged residents. our argument is tested against (1) the household travel survey in 2010, (2) a small-scale survey in 2012, as well as (3) our interviews with local residents in beijing. cardholders' job and residence locations are identified using smart card data (scd) in 2008 and 2010. our analysis is restricted to cardholders that use the same cards in both years. we then classify all identified frs into 20 groups by residence changes (change, no change), workplace changes (change, no change, finding a job, losing a job, and all-time employed) during 2008-2010 and housing place in 2010 (within the fourth ring road or not). the underprivileged degree of each fr is then evaluated using the 2014 scd. to the best of our knowledge, this is one of the first studies for understanding long- or mid-term urban dynamics using immediate "big data", and also for profiling underprivileged residents in beijing in a fine-scale. 
  with the explosion of social media sites and proliferation of digital computing devices and internet access, massive amounts of public data is being generated on a daily basis. efficient techniques algorithms to analyze this massive amount of data can provide near real-time information about emerging trends and provide early warning in case of an imminent emergency (such as the outbreak of a viral disease). in addition, careful mining of these data can reveal many useful indicators of socioeconomic and political events, which can help in establishing effective public policies. the focus of this study is to review the application of big data analytics for the purpose of human development. the emerging ability to use big data techniques for development (bd4d) promises to revolutionalize healthcare, education, and agriculture; facilitate the alleviation of ; and help to deal with humanitarian crises and violent conflicts. besides all the benefits, the large-scale deployment of bd4d is beset with several challenges due to the massive size, fast-changing and diverse nature of big data. the most pressing concerns relate to efficient data acquisition and sharing, establishing of context (e.g., geolocation and time) and veracity of a dataset, and ensuring appropriate privacy. in this study, we provide a review of existing bd4d work to study the impact of big data on the development of society. in addition to reviewing the important works, we also highlight important challenges and open issues. 
  tourism has been an increasingly important factor in global economy, society and environment, accounting for a significant share of gdp and labor force. policy and research on tourism traditionally rely on surveys and economic datasets, which are based on small samples and depict tourism dynamics at low spatial and temporal granularity. anonymous call detail records (cdrs) are a novel source of data, showing enormous potential in areas of high societal value: such as epidemics, , and urban development. this study demonstrates the added value of using cdrs for the formulation, analysis and evaluation of tourism strategies, at the national and local levels. in the context of the european country of andorra, we use cdrs to evaluate marketing strategies in tourism, understand tourists' experiences, and evaluate revenues and externalities generated by touristic events. we do this by extracting novel indicators in high spatial and temporal resolutions, such as tourist flows per country of origin, flows of new tourists, tourist revisits, tourist externalities on transportation congestion, spatial distribution, economic impact, and profiling of tourist interests. we exemplify the use of these indicators for the planning and evaluation of high impact touristic events, such as cultural festivals and sports competitions. 
  we try to answer the question: "can we 'modify' our neighborhoods to make them less vulnerable to flooding?" we minimize flooding vulnerability for a city in the central plain of luzon, by modeling the city as a biological organism with 'traits', and try to 'breed' a 'champion' city (with a low flooding vulnerability) via a genetic algorithm. the result is a description of the traits the barangays (neighborhoods) should have (the 'design' of the city). as far as we can tell, this kind of modeling has not been attempted before. the different components of flooding vulnerability were investigated, and each was given a weight, which allows us to express vulnerability as a weighted sum; this serves as the fitness function for the genetic algorithm. we also allowed non-linear interactions among related but independent components, viz,  and mortality rate, and literacy and radiotv penetration. the two-table system we used to prioritize the components of vulnerability is prone to subjectivity, a common problem in analyses of vulnerability. thus, a sensitivity analysis was done, which gave a design with a 24% decrease in vulnerability alongside a 14% percent decrease in cost, a significant improvement over this initial scenario analysis, where the proposed design had a 12% decrease in vulnerability with a one percent increase in cost. 
  as the rate of incarceration in the united states continues to grow, a large body of research has been primarily focused on understanding the determinants and drivers of federal and state prison growth. however, local jail systems, with 11 million admissions each year, have generated less research attention even though they have a far broader impact on communities. preliminary time trend analysis conducted by the vera institute of justice (vera) uncovered disparities in county jail incarceration rates by geography. contrary to assumptions that incarceration is an urban phenomenon, vera discovered that during the past few decades, pretrial jail rates have declined in many urban areas whereas rates have grown or remained flat in rural counties. in an effort to uncover the factors contributing to continued jail growth in rural areas, vera joined forces with two sigma's data clinic, a volunteer-based program that leverages employees' data science expertise. using county jail data from 2000 - 2013 and county-specific demographic, political, socioeconomic, jail and prison population variables, a generalized estimating equations (gee) model was specified to account for correlations within counties over time. the results revealed that county-level , police expenditures, and spillover effects from other county and state authorities are all significant predictors of local jail rates. in addition, geographic investigation of model residuals revealed clusters of counties where observed rates were much higher (and much lower) than expected conditioned upon county variables. 
  social and behavioral interventions are a critical tool for governments and communities to tackle deep-rooted societal challenges such as homelessness, disease, and . however, real-world interventions are almost always plagued by limited resources and limited data, which creates a computational challenge: how can we use algorithmic techniques to enhance the targeting and delivery of social and behavioral interventions? the goal of my thesis is to provide a unified study of such questions, collectively considered under the name "algorithmic social intervention". this proposal introduces algorithmic social intervention as a distinct area with characteristic technical challenges, presents my published research in the context of these challenges, and outlines open problems for future work. a common technical theme is decision making under uncertainty: how can we find actions which will impact a social system in desirable ways under limitations of knowledge and resources? the primary application area for my work thus far is public health, e.g. hiv or tuberculosis prevention. for instance, i have developed a series of algorithms which optimize social network interventions for hiv prevention. two of these algorithms have been pilot-tested in collaboration with la-area service providers for homeless youth, with preliminary results showing substantial improvement over status-quo approaches. my work also spans other topics in infectious disease prevention and underlying algorithmic questions in robust and risk-aware submodular optimization. 
  mobile phones are now widely adopted by most of the world population. each time a call is made (or an sms sent), a call detail record (cdr) is generated by the telecom companies for billing purpose. these metadata provide information on when, how, from where and with whom we communicate. conceptually, they can be described as a geospatial, dynamic, weighted and directed network. applications of cdrs for development are numerous. they have been used to model the spread of infectious diseases, study road traffic, support electrification planning strategies or map socio-economic level of population. while massive, cdrs are not statistically representative of the whole population due to several sources of bias (market, usage, spatial and temporal resolution). furthermore, mobile phone metadata are held by telecom companies. consequently, their access is not necessarily straightforward and can seriously hamper any operational application. finally, a trade-off exists between privacy and utility when using sensitive data like cdrs. new initiatives such as open algorithm might help to deal with these fundamental questions by allowing researchers to run algorithms on the data that remain safely stored behind the firewall of the providers. 
  in mexico, 25 per cent of the urban population now lives in informal settlements with varying degree of depravity. although some informal neighbourhoods have contributed to the upward mobility of the inhabitants, the majority still lack basic services. mexico city and the conurbation around it, form a mega city of 21 million people that has been growing in a manner qualified as "highly unproductive, (that) deepens inequality, raises pollution levels" and contains the largest slum in the world, neza-chalco-izta. urban reforms are now aiming to better the conditions in these slums and therefore it is very important to have reliable measurement tools to assess the changes that are undergoing. in this paper, we use exploratory factor analysis to define an index of depravity in mexico city, namely the slum severity index (ssi), based on the un-habitats definition of a slum. we apply this novel approach to the census survey of mexico and measure the housing deprivation levels types from 1990 - 2010. the analysis highlights high variability in housing conditions within mexico city. we find that the ssi decreased significantly between 1990 - 2000 due to several policy reforms, but increased between 2000 - 2010. we also show correlations of the ssi with other social factors such as education, health and migration. we present a validation of the ssi using grey level co-occurrence matrix (glcm) features extracted from very-high resolution (vhr) remote-sensed satellite images. finally, we show that the ssi can present a cardinally meaningful assessment of the extent of the difference in depravity as compared to a similar index defined by coneval, a government institution that studies  in mexico. 
  the transparency nature of open data is beneficial for citizens to evaluate government work performance. in indonesia, each government bodies or ministry have their own standard operating procedure on data treatment resulting in incoherent information between agent and likely to miss valuable insight. therefore, our motivation is to show the advantage of open data movement to support unified government decision making. we use the dataset from data.go.id which publish official data from each government bodies. the idea is by using those official but limited data, we can find important pattern. the case study is on human development index value prediction and its clustered nature.   we explore the data pattern using two important data analytics methods classification and clustering procedure. data analytics is the collection of activities to reveal unknown data pattern. specifically, we use artificial neural network classification and k-means clustering. the classification objective is to categorize different level of human development index of cities or region in indonesia based on gross domestic product, number of population in , number of internet user, number of labors and number of population indicators data. we determined which city belongs to four categories of human development stated by undp standard. the clustering objective is to find the group characteristics between human development index and gross domestic product. 
  bangladesh is an over populated developing country where crisis of food is a major issue, it faces different infrastructure problem in every sector. for  alleviation from the country we have to confirm cultivable land to increase the crop production for feeding the over population of the country. this paper focuses on the measurement of cultivable land for cultivation. the main purpose of this paper is to briefly describe how the gis, digital mapping, internet concepts and tools can effectively contribute in the modeling, analysis and visualization phases within an engineering or research project according to the crops by using object detection, object tracking and field mapping in bangladesh. through gis mapping of the agricultural lands, the statistics can be made of how much land is cultivable and each year how much land we are losing. mapping the cultivation land will tell us how much crop we have to import from other countries. enabling real-time gis analysis anytime, anywhere, the implementation of the gis information to a wider aspect. automation is the indicator of the modern civilizations. the system will benefit the food stock of the country according to the harvest. for this research we developed a new interactive system. the system will integrate with gis project data in google earth, first finds highly accurate cluster images and partial images, obtains user feedback to merge or correct these digests, and then the supplementary visual analysis complete the partitioning of the data. this study was conducted at the software laboratory, computer science and engineering department, jahangirnagar university, dhaka, bangladesh in 2013. 
  traditionally health statistics are derived from civil andor vital registration. civil registration in low-income countries varies from partial coverage to essentially nothing at all. consequently the state of the art for public health information in low-income countries is efforts to combine or triangulate data from different sources to produce a more complete picture across both time and space - data amalgamation. data sources amenable to this approach include sample surveys, sample registration systems, health and demographic surveillance systems, administrative records, census records, health facility records and others.   we propose a new statistical framework for gathering health and population data - hyak - that leverages the benefits of sampling and longitudinal, prospective surveillance to create a cheap, accurate, sustainable monitoring platform. hyak has three fundamental components:   1) data amalgamation: a sampling and surveillance component that organizes two or more data collection systems to work together: a) data from hdss with frequent, intense, linked, prospective follow-up and b) data from sample surveys conducted in large areas surrounding the health and demographic surveillance system sites using informed sampling so as to capture as many events as possible;   2) cause of death: verbal autopsy to characterize the distribution of deaths by cause at the population level; and   3) ses: measurement of socioeconomic status in order to characterize  and wealth.   we conduct a simulation study of the informed sampling component of hyak based on the agincourt hdss site in south africa. compared to traditional cluster sampling, hyak's informed sampling captures more deaths, and when combined with an estimation model that includes spatial smoothing, produces estimates mortality that have lower variance and small bias. 
  diversity is a fundamental feature of ecosystems, even when the concept of ecosystem is extended to sociology or economics. diversity can be intended as the count of different items, animals, or, more generally, interactions. there are two classes of stylized facts that emerge when diversity is taken into account. the first are diversity explosions: evolutionary radiations in biology, or the process of escaping ' traps' in economics are two well known examples. the second is nestedness: entities with a very diverse set of interactions are the only ones that interact with more specialized ones. in a single sentence: specialists interact with generalists. nestedness is observed in a variety of bipartite networks of interactions: biogeographic, macroeconomic and mutualistic to name a few. this indicates that entities diversify following a pattern. since they appear in such very different systems, these two stylized facts point out that the build up of diversity is driven by a fundamental probabilistic mechanism, and here we sketch its minimal features. we show how the contraction of a random tripartite network, which is maximally entropic in all its degree distributions but one, can reproduce stylized facts of real data with great accuracy which is qualitatively lost when that degree distribution is changed. we base our reasoning on the combinatoric picture that the nodes on one layer of these bipartite networks can be described as combinations of a number of fundamental building blocks. the stylized facts of diversity that we observe in real systems can be explained with an extreme heterogeneity (a scale-free distribution) in the number of meaningful combinations in which each building block is involved. we show that if the usefulness of the building blocks has a scale-free distribution, then maximally entropic baskets of building blocks will give rise to very rich behaviors. 
  causal mediation analysis can improve understanding of the mechanisms underlying epidemiologic associations. however, the utility of natural direct and indirect effect estimation has been limited by the assumption of no confounder of the mediator-outcome relationship that is affected by prior exposure---an assumption frequently violated in practice. we build on recent work that identified alternative estimands that do not require this assumption and propose a flexible and double robust semiparametric targeted minimum loss-based estimator for data-dependent stochastic direct and indirect effects. the proposed method treats the intermediate confounder affected by prior exposure as a time-varying confounder and intervenes stochastically on the mediator using a distribution which conditions on baseline covariates and marginalizes over the intermediate confounder. in addition, we assume the stochastic intervention is given, conditional on observed data, which results in a simpler estimator and weaker identification assumptions. we demonstrate the estimator's finite sample and robustness properties in a simple simulation study. we apply the method to an example from the moving to opportunity experiment. in this application, randomization to receive a housing voucher is the treatmentinstrument that influenced moving to a low- neighborhood, which is the intermediate confounder. we estimate the data-dependent stochastic direct effect of randomization to the voucher group on adolescent marijuana use not mediated by change in school district and the stochastic indirect effect mediated by change in school district. we find no evidence of mediation. our estimator is easy to implement in standard statistical software, and we provide annotated r code to further lower implementation barriers. 
  stunting, or impaired child growth due to undernutrition, has multiple negative health effects, making it a top global health priority. the current benchmark for classifying stunting assumes a universal model of growth with height-for-age z-score (haz) cutoffs set by the who. however, this universal model may hide hotspots of stunting if populations differ in haz in ways that are independent of undernutrition. we assess the potential magnitude of this bias by decomposing variation in haz from 1,406,609 children from 63 low- and middle-income countries into two components; 1) a component shaped by environmental inputs, , infectious disease, inadequate sanitation, and healthcare access, and 2) a country-specific basal starting point that is independent of such inputs. after removing the effects of numerous environmental inputs, we find that different countries have reliably and substantially different basal starting points in average haz scores (a range of 1.7 sd). these country-specific starting points, which we define as basal haz, are not associated with key indicators of undernutrition (e.g., infant mortality and average calorie deficit). by contrast, average increases in haz above a country's starting point, which we define as accrued haz, show strong correlations with these same variables, suggesting that low accrued haz captures standard definitions of stunting as impaired growth due to undernutrition. using these two components, we show how universal cutoffs can underestimate stunting in specific world regions (e.g., sub-saharan africa and the caribbean), where children in even very deprived situations start off taller. as stunting is a high priority global health problem, standards that are sensitive to such population variation in healthy growth should improve efforts to target those most vulnerable to childhood undernutrition. 
